{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce8f8da",
   "metadata": {},
   "source": [
    "#### Rough Practice of DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab4ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age: 100%|██████████| 3/3 [00:01<00:00,  1.61it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'emotion': {'angry': np.float32(2.4100538e-05), 'disgust': np.float32(1.3212926e-12), 'fear': np.float32(3.7723086e-07), 'happy': np.float32(14.083388), 'sad': np.float32(0.00419326), 'surprise': np.float32(0.00034943348), 'neutral': np.float32(85.91204)}, 'dominant_emotion': 'neutral', 'region': {'x': 256, 'y': 265, 'w': 330, 'h': 330, 'left_eye': (480, 398), 'right_eye': (351, 385)}, 'face_confidence': 0.93, 'gender': {'Woman': np.float32(0.008846078), 'Man': np.float32(99.99116)}, 'dominant_gender': 'Man', 'age': 27}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "\n",
    "result = DeepFace.analyze(\n",
    "    img_path=\"Emotion_Images/sad_image1.jpg\",\n",
    "    actions=['emotion','gender','age'],\n",
    "    enforce_detection=False,\n",
    "    detector_backend=\"opencv\"   # or mtcnn, retinaface, etc.\n",
    ")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "229245fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error :  Face could not be detected in Emotion Images/Backside_image2.jpg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "No face detected\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "\n",
    "result = []\n",
    "\n",
    "try:\n",
    "    result = DeepFace.analyze(\n",
    "        img_path=\"Emotion_Images/happy_image1.jpg\",\n",
    "        actions=['emotion','gender'],\n",
    "        enforce_detection=True,\n",
    "        detector_backend=\"opencv\"   # or mtcnn, retinaface, etc.\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Error : \",str(e))\n",
    "    print(\"No face detected\")\n",
    "\n",
    "for res in result:\n",
    "    print(\"Emotion : \",res['dominant_emotion'])\n",
    "    print(\"Gender : \",res['dominant_gender'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f70760",
   "metadata": {},
   "source": [
    "#### The Emotion Detection Project with DeepFace and CV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba92651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        result = DeepFace.analyze(\n",
    "            frame,\n",
    "            actions=['emotion', 'gender'],\n",
    "            enforce_detection=True,\n",
    "            detector_backend=\"opencv\"\n",
    "        )\n",
    "\n",
    "        for res in result:\n",
    "            dominant_emotion = res['dominant_emotion']\n",
    "            dominant_gender = res['dominant_gender']\n",
    "            region = res['region']  \n",
    "\n",
    "            x, y, w, h = region['x'], region['y'], region['w'], region['h']\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "            text = f\"{dominant_emotion}, {dominant_gender}\"\n",
    "            cv2.putText(frame, text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.8, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    cv2.imshow(\"Emotion & Gender Detection\", frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
